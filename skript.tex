\documentclass[11pt,a4paper]{scrreport}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{colortbl}
\usepackage{listings}
\usepackage{chngcntr}
\usepackage{upgreek}
\usepackage{pgfplots}
\pgfplotsset{compat = newest}
\usepackage{ulem}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{float}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{mindmap}
\usepackage{tikz-network}

\usepackage[backend=biber, style=IEEE]{biblatex}
\addbibresource{literature.bib}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\titlehead{\begin{center}
\includegraphics[scale=0.7]{DHBW.jpg}
\end{center}}
\title{THEOPLUS}
\subtitle{Ergänzende Inhalte der theoretischen Informatik}
\author{Roman Wetenkamp}

\newtheoremstyle{custom}%    <name>
                {10pt}%   <space above>
                {10pt}%   <space below>
                {}%  <body font>
                {}%          <indent amount>
                {\bfseries}% <Theorem head font>
                {.}%         <punctuation after theorem head>
                {\newline}%  <space after theorem head> (default .5em)
                {}%          <Theorem head spec>

\theoremstyle{remark}
\newtheorem{note}{Bemerkung}

\theoremstyle{custom}
\newtheorem{definition}{Definition}[section]
\newtheorem{satz}{Satz}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{example}{Beispiel}[section]

\begin{document}
\maketitle

\section*{Randnotizen}
Dieses Skript ist das Ergebnis meiner Beschäftigung mit weiteren Inhalten der theoretischen Informatik, die über die Vorlesungen zu theoretischer Informatik an der DHBW hinausgehen. Ich möchte mit diesem Skript meine Ergebnisse sichern, für andere nutzbar und zugänglich machen und mich didaktisch ausprobieren. Bei der Auswahl der Inhalte habe ich mich im wesentlichen an den Inhalten der Quellen \parencite{Hopcroft}, \parencite{Sipser} und \parencite{Ben-Ari} und dem Modulhandbuch der DHBW Mannheim für den Studiengang {\glqq}Informatik -- Cyber Security{\grqq} orientiert. 
\paragraph{Mitwirken} Für Fragen, Anmerkungen und Kritik bin ich jederzeit sehr offen. Ich freue mich über E-Mails an \href{mailto:s200376@student.dhbw-mannheim.de}{s200376@student.dhbw-mannheim.de} oder über Issues / Pull Requests im zu diesem Skript dazugehörigen \href{https://www.github.com/RWetenkamp/theoplus}{GitHub-Repository}.
\subsection*{Inhaltsübersicht}
\begin{figure}[h!]
\centering
\begin{tikzpicture}[mindmap, every node/.style={concept, execute at begin node=\hskip0pt}, concept color=blue!20, grow cyclic, level 1/.append style={level distance=4.5cm,sibling angle=90}, level 2/.append style={level distance=3cm,sibling angle=45}]
\node [root concept] {Theoretische Informatik} % root
child { node {Logik} 
	child { node {PROLOG} }
	child { node {Semantik} }
	child { node {Verifikation} }
	child { node {Formalisieren} }	
}
child { node {Berechenbarkeit} 
	child { node {Church-Turing} }
	child { node {Entscheidbarkeit} }
	child { node {Reduzierbarkeit} }
}
child { node {Komplexität} 
	child { node {Zeit} } 
	child { node {Raum} }
	child { node {Hartnäckig-keit} } 
} 
child { node {Formale Sprachen} 
	child { node {Chomsky-Hierarchie} } 
	child { node {Kellerautomaten} }
	child { node {Turing-Maschinen} }
};
\end{tikzpicture}
\caption{Inhaltsübersicht. Eigene Darstellung.}
\end{figure}
\pagebreak
\tableofcontents
\pagebreak
\part{Formale Sprachen}
\chapter{Sprachklassen}
\paragraph{Motivation} Sprachen sind faszinierend: In unseren ersten Lebensjahren lernen wir die Sprache(n) unserer Eltern, noch so intuitiv wie nie wieder. In der Schule kommen Fremdsprachen hinzu, die wir mal mehr, mal weniger gerne lernen. Als Jugendliche experimentieren wir mit der Sprache, verändern sie, um uns von Erwachsenen abzugrenzen, nutzen Sie als Ausdruck unserer Lebenswirklichkeit. Später lernen Sie Programmiersprachen, fügen sie vielleicht scherzhaft der Liste Ihrer Sprachkenntnisse hinzu. Doch das ist weit mehr als ein plumper Nerdwitz: Diese und jene Sprachen eint viel!
\begin{definition}
Eine (formale) Sprache ist eine Menge von Zeichenketten, die aus den Symbolen eines beliebigen Alphabets aufgebaut sind. \parencite[vgl. ][S. 1]{Hopcroft}
\end{definition}
Wenn Sie an das Sprachenlernen im schulischen Kontext denken, vergleichen Sie diese Definition vielleicht mit dem Vokabellernen. Demnach wäre Englisch die Menge aller englischen Wörter. Das erscheint uns falsch: Die bloße Kenntnis aller englischen Begriffe lässt Sie noch lange kein korrektes Englisch sprechen. Dafür gibt es Grammatiken -- Regelwerke, die aussagen, wann ein Satz korrekt ist. Mit ihnen wollen wir uns nun aus formaler Sicht näher beschäftigen.
\section{Die \textsc{Chomsky}-Hierarchie}
In Ihrer Vorlesung haben Sie gelernt, dass es verschiedene Typen von Grammatiken gibt. Höchst"-wahr"-scheinlich wurden kontextfreie Grammatiken eingeführt -- Diese Klassen erweitern wir nun entsprechend einer Hierarchie von \textsc{Noam Chomsky}, der \index{Chomsky-Hierarchie}. Dieser Aufbau verläuft analog zu den Zahlenräumen: Die natürlichen Zahlen $\mathbb{N}$, die Sie zum Zählen nutzen, ergeben zusammen mit ihren negativen Entsprechungen und der Null die ganzen Zahlen $\mathbb{Z}$, dann definieren Sie unendlich viele Zahlen dazwischen und nennen sie die rationalen Zahlen $\mathbb{Q}$. Wozu nach endlich vielen Nachkommastellen aufhören? Sie kommen zu $\mathbb{R}$ und schließlich zu $\mathbb{C}$. Analog zu dieser Teilmengenbeziehungen konstruieren wir nun auch die Sprachklassen der Chomsky-Hierarchie.
\begin{figure}[H]
\centering
\begin{tikzpicture}
\node[draw,ellipse,minimum width=2cm, minimum height=2cm] (regular) at (0,0){Reguläre Grammatiken};
\node[draw,ellipse,minimum width=8cm, minimum height=4cm, label={[anchor=south,above=4mm]270:Kontextfreie Grammatiken}] (kontextfrei) at (0,0){};
\node[draw,ellipse,minimum width=10cm, minimum height=6cm, label={[anchor=south,above=4mm]270:Kontextsensitive Grammatiken}] (kontextsensitiv) at (0,0){};
\node[draw,ellipse, minimum width=12cm, minimum height=8cm, label={[anchor=south,above=4mm]270:Rekursiv aufzählbare Grammatiken}] (rekursiv) at (0,0) {};
\end{tikzpicture}
\caption{Chomsky-Hierarchie formaler Sprachen. Eigene Darstellung.}
\end{figure}
\begin{note}
Eine reguläre Grammatik ist folglich auch eine kontextfreie, kontextsensitive und rekursiv aufzählbare Grammatik, unterliegt jedoch noch einigen weiteren Bedingungen und Beschränkungen als ihre Oberklassen.
\end{note}
Nacheinander -- von innen nach außen -- werden wir nun diese Sprachklassen definieren. 
\section{Typ 3: Reguläre Grammatiken}
Zu Beginn dieses Themengebiets der Theoretischen Informatik widmeten wir uns Automaten. Wir unterschieden zunächst deterministische endliche (DEA, \textit{engl.:} DFA) und nicht-deterministische endliche Automaten (NEA, \textit{engl.:} NFA). Ebenso definierten wir reguläre Sprachen und stellten die Äquivalenz der drei Objekte fest.
\begin{figure}[h!]
\centering
\begin{tikzpicture}
\node[draw, rectangle] (nea) at (4,4) {Nichtdeterministische endliche Automaten};
\node[draw, rectangle] (dea) at (0,2) {Deterministische endliche Automaten};
\node[draw, rectangle] (reg) at (4,0) {Reguläre Ausdrücke};
\node[draw, rectangle] (nea_e) at (8,2) {NEA mit $\epsilon$-Transitionen};
\draw[->] (nea) -- (dea);
\draw[->] (dea) -- (reg);
\draw[->] (reg) -- (nea_e);
\draw[->] (nea_e) -- (nea); 
\end{tikzpicture}
\caption{Äquivalenzkonstruktionen (Quelle: \parencite[][S. 30]{Hopcroft})}
\label{eqcircle}
\end{figure}
Wir werden reguläre Grammatiken anhand der nächstgrößeren Klasse, der kontextfreien Grammatiken, definieren. So werden reguläre Grammatiken zu kontextfreien Grammatiken, die spezielle Bedingungen erfüllen. 
\begin{definition} \label{kfG}
Eine \textbf{kontextfreie Grammatik} $G$ ist ein 4-Tupel $G = (V, T, P, S)$, wobei gilt:
\begin{itemize}
\item $V$ bezeichnet eine Menge von Variablen.
\item $T$ bezeichnet eine Menge von Terminalen.
\item $P$ bezeichnet eine Menge von Produktionen (also Regeln), wobei eine Produktion $A$ der Form $ A \rightarrow \alpha$ mit $\alpha \in (V \cup T)*$ ist.
\item $S$ bezeichnet ein Startsymbol. $S \in V$.
\end{itemize}
Es gilt: $V \cap T = \emptyset$.
\end{definition}
Betrachten wir beispielsweise eine Grammatik, die den Aufbau von Log-Einträgen beschreibt:
\begin{example}
$
G = (\{\text{Start}, \text{Type}, \text{Text}, \text{ErrorCode}, \text{TimeStamp}\}, \{\texttt{INFO}, \texttt{WARNING}, \texttt{ERROR}, \allowbreak \texttt{:}, \texttt{.}, \texttt{ }, \texttt{ -- }, \texttt{(}, \texttt{)}, \text{NUMBER}, \allowbreak \text{STRING}\}, P, \text{Start}) $ \\
Wobei $P$ aus folgenden Regeln besteht:
\begin{align*}
\text{Start} &\rightarrow \text{TimeStamp} \texttt{ -- } \text{Type} \texttt{ : } \text{Text} \texttt{ ( } \text{ErrorCode} \texttt{ ) } \\
\text{Type} &\rightarrow \texttt{INFO} \mid \texttt{WARNING} \mid \texttt{ERROR} \\
\text{TimeStamp} &\rightarrow \text{NUMBER} \texttt{ . } \text{NUMBER} \text{ . } \text{NUMBER} \texttt{ } \text{NUMBER} \texttt{ : } \text{NUMBER} \texttt{ : } \text{NUMBER} \\
\text{Text} &\rightarrow \text{STRING } \text{Text} \mid \text{NUMBER } \text{Text} \mid \epsilon \\
\text{ErrorCode} &\rightarrow \text{NUMBER} \mid \epsilon
\end{align*} \\
Häufig wird die Grammatik nicht mehr als Tupel angegeben, sondern lediglich als Aufzählung ihrer Produktionen. Dies ist dann möglich, wenn die Definition entsprechend beschränkt wird -- dann ist das Startsymbol direkt ablesbar und ebenso auch die Mengen der Terminale und Variablen.
\end{example}
Kommen wir nun zu \textbf{regulären Grammatiken}.
\begin{definition}
Eine \textbf{kontextfreie Grammatik} ist genau dann \textbf{regulär}, falls sie rechts-linear oder links-lineare ist. Rechts-linear ist eine Grammatik genau dann, wenn ihre Produktionen von der Form
\[A \rightarrow w\text{ }B\] oder \[A \rightarrow\text{ }w\] und $A, B$ Variablen sind und $w$ eine Zeichenkette von Terminalen ist. Entsprechend definieren wir die Links-Linearität: Falls alle Produktionen der Grammatik der Form
\[A \rightarrow B\text{ }w\] oder \[A \rightarrow w\] sind, so ist die Grammatik links-linear.
\end{definition}
Betrachten wir ein Beispiel für eine reguläre Grammatik:
\begin{example}
Die Sprache $\text{a}(\text{b})*$ wird von der rechts-linearen Grammatik 
\begin{align*}
S &\rightarrow \text{a } A \\
A &\rightarrow \text{b } A \mid \epsilon
\end{align*}
und von der links-linearen Grammatik
\begin{align*}
S &\rightarrow S \text{ b } | \text{ a}
\end{align*}
erzeugt.
\end{example}
\begin{note}
Wir erkennen eine Rekursivität: In beiden Fällen gibt es mindestens eine Variable, die sich selbst in einer ihrer Produktionen enthält. Daher wird die Links-Linearität bzw. Rechts-Linearität gelegentlich auch \textbf{Links-Rekursion} oder \textbf{Rechts-Rekursion} genannt.
\end{note}
Nun erinnern wir uns an den Zusammenhang zwischen regulären Mengen und endlichen Automaten -- gilt etwas Entsprechendes auch für reguläre Grammatiken?
\begin{satz} \label{eqSatz}
Reguläre Grammatiken und endliche Automaten sind äquivalent.
\end{satz}
Wir geben an dieser Stelle nur eine Beweisidee an, der vollständige Beweis ist bei \parencite[][S. 228]{Hopcroft} zu finden. Um die Aussage zu beweisen, nehmen wir an, $L = L(G)$ gilt für eine rechts-lineare Grammatik $G = (V, T, R, S)$. Dann können wir einen NEA mit $\epsilon$-Übergangen aus den Ableitungsschritten konstruieren. Die Zustände dieses Automaten sind jeweils die linke oder rechte Seite der Produktionen. Nach Abbildung \ref{eqcircle} (samt entsprechender Beweise) erhalten wir nun, dass die rechts-lineare Grammatik eine reguläre Menge erzeugt. Für eine links-lineare Grammatik gilt das Beweisprinzip analog.
\section{Typ 2: Kontextfreie Grammatiken}
Kontextfreie Grammatiken haben wir bereits im vorherigen Abschnitt definiert und genutzt, um reguläre Grammatiken zu definieren. Dies sparen wir uns also hier uns verweisen auf \ref{kfG}.
\paragraph{Wofür nutzen wir kontextfreie Grammatiken?} Wie reguläre Grammatiken auch nutzen wir kontextfreie Grammatiken für die Definition und Übersetzung von Programmiersprachen. Eine wichtige Aufgabe, die durch reguläre Grammatiken nicht abgebildet werden kann, ist die korrekte Interpretation von geklammerten arithmetischen Ausdrücken (z.B. $(a + b ) * c$) oder auch Code-Abschnitten wie \texttt{{\textbackslash}begin$\lbrace \rbrace$} und \texttt{{\textbackslash}end$\lbrace \rbrace$} in {\LaTeX}. Über reguläre Sprachen ließen sich diese Strukturen nicht abbilden. \parencite[vgl. ][S. 81]{Hopcroft}
\subsection{Kellerautomaten}
Nun besinnen wir uns nochmal auf Satz \ref{eqSatz} zurück. Reguläre Grammatiken, also der Typ 3 der Chomsky-Hierarchie, sind äquivalent zu endlichen Automaten. Diese Eigenschaft ließ sich nutzen, um reguläre Grammatiken zu visualisieren und Automatenoperationen auf ihnen auszuführen. Mittlerweile befinden wir uns in einem anderen Chomsky-Typ -- das legt nahe, dass kontextfreie Grammatiken auch einen Teil solcher Grammatiken umfassen, die nicht äquivalent zu endlichen Automaten sind. Doch gibt es ein Automatenkonzept für kontextfreie Grammatiken? Ja, die Kellerautomaten.
\paragraph{Informatikerbiotop Keller} Vielleicht kommt Ihnen der Keller heimisch vor, vielleicht haben Sie dort (wie der Vater eines Schulfreundes) ihr Büro eingerichtet, von dem aus sie tagelang an einer Software herumprogrammieren, die Sie dann für viel Geld verkaufen. Vielleicht sind sie so beschäftigt, dass sich mit Essensresten verzierte Teller übereinander stapeln, weil Sie gutem Essen nie mehr Relevanz als einer Nebenbeitätigkeit beimessen. Behalten Sie diesen Tellerstapel -- doch stellen Sie sich sie sauber vor, in einem ordentlichen Stapel auf einer Feder wie in einer Mensa-Schlange Ihrer Hochschule. Jeder Gast nimmt sich einen Teller vom Stapel, sobald der Stapel leer ist, werden neue Teller nachgelegt. Der letzte nachgelegte Teller ist der erste, der anschließend heruntergenommen wird -- wir folgern: Ein Last-in-First-out-Prinzip (LIFO). Nun spätestens sollte Ihnen sofort die dazugehörige Datenstruktur einfallen, falls Sie den Begriff nicht sowieso direkt mit {\glqq}Keller{\grqq} assoziiert haben: \textbf{Stack}.
Wir ergänzen endliche Automaten um einen Stack, der nun mit beeinflusst, welche Zustandsübergänge erfolgen.
\begin{definition}
Ein Kellerautomat $M$ ist ein System $(Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$, wobei ...
\begin{itemize}
\item $Q$ eine endliche Menge von Zuständen
\item $\Sigma$ ein Eingabealphabet
\item $\Gamma$ ein Kelleralphabet
\item $q_0 \in Q$ ein Anfangszustand
\item $Z_0 \in \Gamma$ ein Anfangssymbol
\item $F \subseteq Q$ eine Menge von Endzuständen
\item $\delta$ eine Abbildung der Form $Q \times (\Sigma \cup \lbrace \epsilon \rbrace) \times \Gamma \mapsto \mathcal{P}(Q \times \Gamma*)$
\end{itemize}
ist.
\end{definition}
Die Ähnlichkeit zur Definition endlicher Automaten ist augenscheinlich. Hinzu kommen ein Kelleralphabet (Worte, die auf den Stack gelegt werden), ein Anfangssymbol, dass sich zuallererst auf dem Stack befindet und eine veränderte Zustandsübergangsfunktion, die nun auch das oberste Element des Stacks mitberücksichtigt. 
\[\delta(q, a, Z) = \lbrace (p_i, \gamma_i), ..., (p_m, \gamma_m) \rbrace \]
Hier bezeichnet $q$ den aktuellen Zustand, $a$ das nächste eingelesene Element von $\Sigma$ und $Z$ das oberste Kellersymbol. $p_i$ ist Element der Zustandsmenge $Q$ und $\gamma_i$ eine Folge von Symbolen des Kelleralphabets. Grundsätzlich existieren drei Stack-Operationen:
\begin{itemize}
\item \textbf{Hinzufügen eines Elements}. Liegt vor der Operation ein $X$ auf dem Stack und soll ein $Y$ hinzugefügt werden, so ist der Stack anschließend $YX$.
\item \textbf{Entfernen eines Elements}. $XY \rightarrow Y$
\item \textbf{Unverändertlassen}.
\end{itemize}

\section{Typ 1: Kontextsensitive Grammatiken}
\section{Typ 0: Rekursiv aufzählbare Grammatiken}
\pagebreak
\normalem
\printbibliography
\end{document}